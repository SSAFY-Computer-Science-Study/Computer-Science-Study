# 06. 메모리와 캐시 메모리

## 06-1. RAM의 특징과 종류

> `휘발성 저장 장치`   `비휘발성 저장 장치`   `DRAM`  `SRAM`  `SDRAM`  `DDR SDRAM`
> 

우리가 "메모리"라고 부르는 것은 주기억장치인 RAM과 ROM 중 RAM을 의미

### RAM의 특징

- **RAM**은 *Random Access Memory*의 약자로 실행할 프로그램의 명령어와 데이터가 저장됨
- 전원을 끄면 RAM에 저장된 데이터는 모두 날아감
- **휘발성 저장 장치** *volatile memory*
    - 전원을 끄면 저장된 내용이 사라짐
    - **예)** RAM
- **비휘발성 저장 장치** *non-volatile memory*
    - 전원이 꺼져도 저장된 내용이 유지되는 저장 장치
    - **예)** 하드디스크, SSD, CD-ROM, USB 메모리 등의 보조기억장치

![Image](https://github.com/user-attachments/assets/232aad07-dfba-4f08-96eb-5aac4cc7e3f8)

- 보조기억장치는 전원을 꺼도 내용을 유지하지만, CPU는 보조기억장치에 직접 접근 x
    - → **보조기억장치**에는 `보관할 대상`을 저장하고, **RAM**에는 `실행할 대상`을 저장함
- 실행하고자 하는 프로그램이 보조기억장치에 있다면 이를 RAM으로 복사하여 저장한 뒤 실행

### RAM의 용량과 성능

RAM 용량은 컴퓨터 성능에 어떤 영향을 미칠까?

- CPU가 실행하고 싶은 프로그램이 보조기억장치에 있다면 이를 RAM으로 가져와야 할 텐데, RAM 용량이 적다면 보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어짐
- but, **RAM 용량이 충분히 크다면** 보조기억장치에서 많은 데이터를 가져와 미리 RAM에 저장할 수 있어 **많은 프로그램을 동시에 빠르게 실행하는 데 유리함**
- RAM 용량이 커질수록 그에 비례하여 프로그램 실행 속도도 빨라질까?
    - 아니다!
    - 어느 정도 증가하지만, 필요 이상으로 용량이 커졌을 때 속도가 그에 비례하여 증가하지는 않음!

### RAM의 종류

- **DRAM** D*ynamic RAM*
    - 저장된 데이터가 **동적으로 변하는(사라지는)** RAM
    - 시간이 지나면 저장된 데이터가 점차 사라지기 때문에 데이터 소멸을 막기 위해 **일정 주기로 데이터 재활성화(다시 저장)**해야 함
    - 우리가 `일반적으로 사용하는 메모리 RAM` = DRAM
    - **소비 전력이 비교적 낮고 저렴하고 집적도가 높아 대용량으로 설계하기 용이**
- **SRAM** S*tatic RAM*
    - 저장된 데이터가 변하지 않는 RAM
    - 시간이 지나도 저장된 데이터가 사라지지 않음 → 재활성화 필요 X
        - **(주의)** 휘발성 메모리! - 전원이 꺼지면 데이터 사라짐
    - 일반적으로 DRAM보다 속도도 빠름
    - DRAM보다 집적도가 낮고 소비 전력이 크고 가격도 비쌈
    - → SRAM은 메모리가 아닌 **대용량으로 만들 필요는 없지만 속도가 빨라야 하는 저장 장치** ⇒ **`캐시 메모리`**에서 사용
    
    ![Image](https://github.com/user-attachments/assets/85bf3041-551e-4a2e-a831-626fe56b951c)
    
- **SDRAM** S*ynchronomous Dynamic RAM*
    - **`클럭 신호와 동기화된`** 발전된 형태의 DRAM
    - 클럭 타이밍에 맞춰(클럭 마다) CPU와 정보를 주고받을 수 있음
- **DDR SDRAM** D*ouble Data Rate SDRAM*
    - **최근 가장 흔히 사용되는 RAM ⇒ DDR4 SDRAM (SDR SDRAM의 16배)**
    - **`대역폭을 넓혀` 속도를 빠르게 한 `SDRAM`**
    - **대역폭** *data rate*
        - 데이터를 주고 받는 길의 너비
    
    ![Image](https://github.com/user-attachments/assets/867554c8-923b-4c83-9b34-86984f51101f)
    
    - **한 클럭에 주고 받을 수 있는 데이터 양**이 SDRAM의 `2**배**`
        - 한 클럭에 한 번씩 CPU와 데이터를 주고받을 수 있는 SDRAM에 비해 DDR SDRAM은 한 클럭에 두 번씩 CPU와 데이터를 주고받을 수 있음
    - **전송 속도** 역시 `2배` 빠름
        - 이 관점에서 **SDRAM = SDR SDRAM** S*ingle Sata Rate SDRAM* 이라고도 부름
    - +) DDR SDRAM * 2배  = **DDR2 SDRAM (SDRAM의 4배)**
    DDR2 SDRAM * 2배 = **DDR3 SDRAM (SDRAM의 8배)**

<br>


## 06-2. 메모리의 주소 공간

> `물리 주소`   `논리 주소`   `MMU`  `베이스 레지스터`   `한계 레지스터`
> 

**Q. CPU와 실행 중인 프로그램은 현재 메모리 몇 번지에 무엇이 저장되어 있는지 다 알고 있을까?**

아니다. 메모리에는 새롭게 실행되는 프로그램이 적재되고, 실행이 끝난 프로그램이 삭제되며 정보가 시시각각 변함. 또한 같은 프로그램을 실행하더라도 실행할 때마다 적재되는 주소가 달라질 수 있음. 

### 물리 주소와 논리 주소

![Image](https://github.com/user-attachments/assets/5b69e9dd-58f1-43c3-91e4-8f2b76cfdedb)

- **물리 주소** *physical address*
    - 메모리 하드웨어가 사용하는 주소
    - 정보가 실제로 저장된 하드웨어상의 주소
- **논리 주소** *logical address*
    - CPU와 **실행 중인 프로그램**이 사용하는 주소
    - 실행 중인 프로그램 각각에 부여된 0번지부터 시작되는 주소
    - 다른 프로그램의 메모리 내용을 알 필요 없으니 자신만을 위한 장소 사용.

### 논리 주소와 물리 주소 간의 변환

논리 주소와 물리 주소 간의 변환이 이루어져야 CPU와 메모리가 소통 가능

- **메모리 관리 장치 MMU;** *Memory Management Unit*
    - CPU와 주소 버스 사이에 위치
    - **CPU가 발생시킨 논리 주소**에 **베이스 레지스터 값을 더하여** 논리 주소를 물리 주소로 변환
        
        ![Image](https://github.com/user-attachments/assets/1287ad1d-df3c-4312-be0f-f32ec33224d1)
        
- **베이스 레지스터**
    - **프로그램**의 가장 작은 **물리 주소** = 프로그램의 첫 물리 주소
- **논리 주소**
    - 프로그램의 시작점으로부터 떨어진 거리

### 메모리 보호 기법

> Q. 만약 프로그램의 논리 주소 영역을 벗어난 주소에 접근하려고 한다면?
> 
> 
> 당연히 실행되어서는 안된다! 따라서 다른 프로그램의 영역을 침범할 수 있는 명령어는 위험하기 때문에 **논리 주소 범위를 벗어나는 명령어 실행을 방지**하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법이 필요!
> 
- **한계 레지스터** *limit register*
    - **논리 주소의 최대 크기**를 저장
    - 베이스 레지스터 값 ≤ **프로그램의 물리 주소** < 베이스 레지스터 값 + 한계 레지스터 값
- CPU가 **접근하려는 논리 주소는 한계 레지스터가 저장한 값보다 커서는 안됨**
- CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터 값보다 작은지 항상 검사
    
    → 한계 레지스터 값보다 큰 값에 접근하려고 한다면 **인터럽트(트랩)** 발생시켜 실행을 중단
    
- **결론**
    - 실행 중인 프로그램의 **독립적인 실행 공간**을 확보하고 하나의 프로그램이 다른 프로그램을 침범하지 못하게 보호

![Image](https://github.com/user-attachments/assets/b4f0a6d3-dc7a-48d8-aa2e-53ac21ae2cb8)


<br>


## 06-3. 캐시 메모리

> `저장 장치 계층 구조`   `캐시 메모리`   `캐시 적중률`   `참조 지역성의 원리`
> 

CPU가 연산을 빨리 한다 해도 메모리에 접근하는 시간이 느리면 CPU의 빠른 속도는 쓸모가 없기 때문에 이를 극복하기 위해 **캐시 메모리** 등장

캐시 메모리의 탄생 배경과 특징을 이해하기 위해 **저장 장치 계층 구조**를 이해하자 

### 저장 장치 계층 구조 *memory hierarchy*

**빠른 저장 장치**와 **용량이 큰 저장 장치**는 양립이 어려움

> 1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.
> 

즉, 저장 장치마다 장단점이 명확하기 때문에 컴퓨터는 다양한 저장장치를 모두 사용함

- **저장 장치 계층 구조**
    - 컴퓨터가 사용하는 **저장 장치**를 `CPU에 얼마나 가까운가`를 기준으로 계층적으로 나타낸 것
    
    ![Image](https://github.com/user-attachments/assets/e07a9463-d9a9-4c5d-b27e-18200f7cffe6)
    

### 캐시 메모리

CPU가 메모리에 접근하는 속도는 레지스터에 접근하는 속도보다 느리다. 그럼에도 불구하고 CPU는 프로그램을 실행하는 과정에서 메모리에 빈번히 접근해야 함 → 따라서 이를 극복하기 위해 **캐시 메모리**가 등장 

- **캐시 메모리** *cache memory*
    - CPU와 메모리 사이에 위치
    - **레지스터**보다 용량이 크고 **메모리**보다 빠른 **SRAM** 기반의 저장 장치
    - CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 탄생
        - CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가져와 활용
            
            ![Image](https://github.com/user-attachments/assets/92b671b3-0c14-428a-ad4f-724d9d402847)
            
- **캐시 메모리 계층**
    - **CPU(코어)**와 가까운 순서대로 계층 구성
    - 가까운 순으로 **L1 캐시** *Level 1*, **L2 캐시** *Level 2*, **L3 캐시** *Level 3*
        
        ![Image](https://github.com/user-attachments/assets/34197c45-8356-446a-9c59-9a9e1a15bce6)
        
    - 가까울수록 용량이 작고 속도가 빠르며 가격이 비쌈
    - CPU가 데이터가 필요하다고 판단하면 **L1 캐시부터 검색하여 없다면 L2, L3 순서로 검색**
    - **멀티 코어 프로세서**에서는 일반적으로 L1, L2 캐시는 코어마다 할당, L3 캐시는 여러 코어가 공유
        
       ![Image](https://github.com/user-attachments/assets/42991fd7-0a74-47f4-92de-4d03da355760)
        

> ### ✅ 분리형 캐시 *split cache*  
>  
> 코어와 가장 가까운 **L1 캐시**는 조금이라도 **접근 속도를 빠르게 만들기 위해** 명령어만을 저장하는 캐시인 **L1I 캐시**와 데이터만을 저장하는 L1 캐시인 **L1D 캐시로 분리**하는 경우  
>   
> ![Image](https://github.com/user-attachments/assets/32f4d0c0-35f0-42a3-9314-028ca4ef64b6)
> 

![Image](https://github.com/user-attachments/assets/5bd133b5-5aaf-4258-8967-2a6b1b57e1c7)

### 참조 지역성 원리

캐시 메모리는 메모리보다 용량이 작기 때문에 메모리에 있는 모든 내용을 가져다 저장할 수 없음. 따라서 메모리가 보조기억장치의 일부를 복사하여 저장하는 것처럼 캐시 메모리는 메모리의 일부를 복사하여 저장함.

**보조기억장치**는 **`전원이 꺼져도** 기억할 대상`을 저장하고, **메모리**는 **`실행 중인 대상`**을 저장한다면 **캐시 메모리**는 **`CPU가 사용할 법한 대상`**을 예측하여 저장함

- **캐시 히트** *cache hit*
    - 자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 **캐시 메모리 내 데이터가 CPU에서 활용된 경우**
- **캐시 미스** *cache miss*
    - 자주 사용될 것으로 예측하여 캐시 메모리에 저장했지만, 예측이 틀려 **메모리에 필요한 데이터를 직접 가져와야 하는 경우**
    - CPU가 직접 메모리에 접근해야하므로 캐시 메모리의 이점을 활용X → 자주 발생하면 **성능 저하** 발생
- **캐시 적중률** *cache rate*
    - 캐시가 히트되는 비율
    - `캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)`
    - 우리가 사용하는 컴퓨터의 캐시 적중률은 대략 **85~95%**
    - 캐시 적중률이 높으면 CPU의 메모리 접근 횟수를 줄일 수 있음
- **참조 지역성의 원리** *locality of reference, principle of locality*
    - 캐시 적중률을 높이려면 CPU가 사용할 법한 데이터를 잘 알아야 함!
    - **캐시 메모리**는 `참조 지역성의 원리`에 따라 **메모리에서 가져올 데이터를 결정**
    - **CPU가 `메모리에 접근할 때의 주된 경향`을 바탕으로 만들어진 원리**
        > ✅ 메모리 접근의 주된 경향  
        > 
        > 1. CPU는 **최근에 접근했던 메모리 공간**에 다시 접근하려는 경향이 있다. (`시간 지역성`)  
        > 2. CPU는 **접근한 메모리 공간 근처**를 접근하려는 경향이 있다. `(공간 지역성`)  
        
- **시간 지역성** *temporal locality*
    - CPU가 **최근에 접근했던 메모리 공간**에 다시 접근하려는 경향
    - **예)** 프로그래밍을 할 때 어떤 값을 변수에 저장해놓고 사용하는데 변수에 해당하는 값은 프로그램이 실행되는 동안 여러 번 사용
- **공간 지역성** *spatial locality*
    - CPU가 **접근한 메모리 공간 근처를 접근**하려는 경향
    - **예)** 프로그램은 보통 관련 데이터끼리 한데 모여 있음, 하나의 프로그램 내에서도 관련 있는 데이터는 모여서 저장됨 → 프로그램을 실행할 때 모여있는 공간 근처를 집중적으로 접근하게 됨
